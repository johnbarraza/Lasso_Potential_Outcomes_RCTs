using Pkg
using CSV
using DataFrames
using Statistics
using Random
using GLMNet
using Plots
using LinearAlgebra

# -----------------------------------------------------------
# 1. Cargar datos
# -----------------------------------------------------------
df = CSV.read("Districtwise_literacy_rates.csv", DataFrame)

# Eliminar valores faltantes
dropmissing!(df)

# -----------------------------------------------------------
# 2. Variables
# -----------------------------------------------------------
y = Matrix(df[:, [:FEMALE_LIT]])[:,1]   # variable dependiente
X_low = Matrix(df[:, [:MALE_LIT]])      # modelo simple
X_high = Matrix(df[:, [:MALE_LIT, :TOTPOPULAT, :P_URB_POP, :SEXRATIO,
                       :OVERALL_LI, :AREA_SQKM, :TOT_6_10_15, :TOT_11_13_15,
                       :SCH1, :SCH2, :SCH3]])

# Train/Test split
Random.seed!(42)
n = nrow(df)
idx = shuffle(1:n)
train_size = Int(floor(0.7n))
tr = idx[1:train_size]
te = idx[train_size+1:end]

# -----------------------------------------------------------
# 3. Modelo simple (low-dimensional)
# -----------------------------------------------------------
cv_low = glmnetcv(X_low[tr,:], y[tr], alpha=1)
λ_low = cv_low.lambda[argmin(cv_low.meanloss)]

fit_low = glmnet(X_low[tr,:], y[tr], alpha=1, lambda=[λ_low])
ŷ_low = predict(fit_low, X_low[te,:], λ_low)[:,1]

r2_low = 1 .- sum((y[te] .- ŷ_low).^2) / sum((y[te] .- mean(y[te])).^2)
coefs_low = coef(fit_low, λ_low)
nnz_low = count(!iszero, coefs_low[2:end])

println("R² (simple) = ", round(r2_low, digits=3),
        " | λ* = ", λ_low,
        " | #coef≠0 = ", nnz_low)

# -----------------------------------------------------------
# 4. Modelo high-dimensional (polinómico)
# -----------------------------------------------------------
# (para simplificar: se usan las features originales, sin polinomios de sklearn)
cv_high = glmnetcv(X_high[tr,:], y[tr], alpha=1)
λ_high = cv_high.lambda[argmin(cv_high.meanloss)]

fit_high = glmnet(X_high[tr,:], y[tr], alpha=1, lambda=[λ_high])
ŷ_high = predict(fit_high, X_high[te,:], λ_high)[:,1]

r2_high = 1 .- sum((y[te] .- ŷ_high).^2) / sum((y[te] .- mean(y[te])).^2)
coefs_high = coef(fit_high, λ_high)
nnz_high = count(!iszero, coefs_high[2:end])

println("R² (flexible) = ", round(r2_high, digits=3),
        " | λ* = ", λ_high,
        " | #coef≠0 = ", nnz_high)

# -----------------------------------------------------------
# 5. Path de coeficientes
# -----------------------------------------------------------
alphas = exp10.(range(4, -3, length=100)) # de 10^4 a 10^-3
fit_path = glmnet(X_high[tr,:], y[tr], alpha=1, lambda=alphas)

plot()
for j in 1:size(fit_path.betas, 1)
    plot!(alphas, fit_path.betas[j,:], lw=1, label=false)
end
xscale!(:log10)
xlabel!("λ (alpha)")
ylabel!("Coeficientes")
title!("Trayectoria de coeficientes LASSO")
hline!([0], linestyle=:dash, color=:black)
savefig("lasso_path_julia.png")
